{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Process for Macdonald Nutrients data\n",
    "This a ETL process to scrap the website of Macdonald and extract the food nutrients data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract (E) Step\n",
    "For this step we are going to use Scraping method because the data is locate in a website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.mcdonalds.com\"\n",
    "MENU_URL = \"https://www.mcdonalds.com/us/en-us/full-menu.html\"\n",
    "\n",
    "response = requests.get(MENU_URL)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "foods_content = soup.find(id='maincategorycontent')\n",
    "\n",
    "# get categories of food\n",
    "categories_divs = foods_content.find_all(\"div\", class_=\"productListing\")\n",
    "\n",
    "# Removing combos categories\n",
    "for index in [5, 7]: del categories_divs[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203057\n"
     ]
    }
   ],
   "source": [
    "# Understanding the structure of the food category and Items content\n",
    "\n",
    "test_category_div = categories_divs[1] # Second Category div\n",
    "# print(test_category_div)\n",
    "\n",
    "# Getting Category Title\n",
    "test_category_title = test_category_div.find(\"h2\", class_=\"mcd-category-page__sub-heading\").text\n",
    "#print(test_category_title)\n",
    "\n",
    "# Getting food list items\n",
    "test_food_items = test_category_div.find_all('li', class_=\"mcd-category-page__item\")\n",
    "#print(test_food_items)\n",
    "\n",
    "test_food_item = test_food_items[20] # First Food List item\n",
    "#print(test_food_item)\n",
    "\n",
    "# Getting data-at attribute that contains the id of the food\n",
    "test_data_attr = test_food_item.find('a', class_=\"mcd-category-page__item-link\")['data-at']\n",
    "\n",
    "test_food_id = test_data_attr.split(\":\")[-2] # Cleaning the string to get the id of the food\n",
    "print(test_food_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This blocks of codes if for getting food ids\n",
    "\n",
    "def get_category_title(category_div):\n",
    "    category_title = category_div.find(\"h2\", class_=\"mcd-category-page__sub-heading\").text\n",
    "    return category_title\n",
    "\n",
    "\n",
    "def get_category_foods(category_div):\n",
    "    # Getting food list items\n",
    "    food_items = category_div.find_all('li', class_=\"mcd-category-page__item\")\n",
    "    return food_items\n",
    "\n",
    "\n",
    "def get_food_id(food_li):\n",
    "    # Getting data-at attribute that contains the id of the food\n",
    "    data_attr = food_li.find('a', class_=\"mcd-category-page__item-link\")['data-at']\n",
    "    \n",
    "    # Detecting valid value to apply the cleaning\n",
    "    if \":\" in data_attr:\n",
    "        food_id = data_attr.split(\":\")[-2] # Cleaning the string to get the id of the food\n",
    "        return food_id\n",
    "\n",
    "food_ids_list = []\n",
    "\n",
    "for category_div in categories_divs:\n",
    "    category_foods = get_category_foods(category_div)\n",
    "\n",
    "    for food_li in category_foods:\n",
    "        food_id = get_food_id(food_li)\n",
    "        # When the data is not valid return None, that is why we verify is return None to not add it to the list.\n",
    "        if food_id != None:\n",
    "            food_ids_list.append(food_id)\n",
    "\n",
    "food_ids_list = set(food_ids_list) # Removing repeated data\n",
    "food_ids_list = list(food_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(food_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Food Details data\n",
    "The nutrients data in the Details page is generated with javascript. In this case we can use a framework like selenium to generate the javascript codes, but there is another easier posible solutions. This solution is verifying if the page use a API to catch that data. In this case the dare is catch in a json format and it is fetch using this url format. In the item attribute is where we are going to put the id of each product to fetch the detail data about the food.\n",
    "\n",
    "https://www.mcdonalds.com/wws/json/getItemDetails.htm?country=US&language=en&showLiveData=true&item=200301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all foods json data\n",
    "def fetch_food_json_data(food_id):\n",
    "    url = f\"https://www.mcdonalds.com/wws/json/getItemDetails.htm?country=US&language=en&showLiveData=true&item={food_id}\"\n",
    "    json_data = requests.get(url).json()\n",
    "    return json_data\n",
    "\n",
    "food_json_list = []\n",
    "\n",
    "for food_id in food_ids_list:\n",
    "    json_data = fetch_food_json_data(food_id)\n",
    "    food_json_list.append(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult_dv': '',\n",
       " 'child_dv': {},\n",
       " 'hundred_g_per_product': '86.2',\n",
       " 'id': 2,\n",
       " 'name': 'Calories',\n",
       " 'nutrient_name_id': 'calories',\n",
       " 'uom': 'Cal.',\n",
       " 'uom_description': 'Cal.',\n",
       " 'value': '210',\n",
       " 'woman_dv': {}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_json_list[0]['item']['nutrient_facts']['nutrient'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform (T) Step\n",
    "Righ now we have a lot of data of each food or product, but fot this ETL we need a few of data about Nutrients. In this step we are going to get the necesary data from the json and give it a correspondent strtucture.\n",
    "\n",
    "The data that we are going to collet are:\n",
    "* Calories (Cal.)\n",
    "* Total Fat (g)\n",
    "* Total Carbohydrates (g)\n",
    "* Protein (g)\n",
    "* Saturated Fat (g)\n",
    "* Dietary Fiber (g)\n",
    "* Calcium (mg)\n",
    "* Trans Fat (g)\n",
    "* Total Sugars (g)\n",
    "* Iron (mg)\n",
    "* Cholesterol (mg)\n",
    "* Vitamin D (mcg)\n",
    "* Potassium (mg)\n",
    "* Sodium (mg)\n",
    "* phosphorus (mg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nuntrient_value(nutrient_facts_json, nutrient_id):\n",
    "    nutrients = nutrient_facts_json['nutrient']\n",
    "    \n",
    "    for nutrient in nutrients:\n",
    "        if nutrient['nutrient_name_id'] == nutrient_id:\n",
    "            return float(nutrient['value']) # Converting value to float\n",
    "        \n",
    "\n",
    "def structure_food_data(json_data):\n",
    "    nutrient_facts = json_data['nutrient_facts']\n",
    "    \n",
    "    # like 5 food item json do not offers nutrient_facts data, so we verify that to not appended to the list\n",
    "    # And like 1 food item json do not offers category data, so we remove it\n",
    "    if len(nutrient_facts) != 0 and len(json_data['default_category']) != 0:\n",
    "        data = {\n",
    "            \"food_name\": json_data['item_name'],\n",
    "            \"category\": json_data['default_category']['category']['name'],\n",
    "            \"calories_cal\": get_nuntrient_value(nutrient_facts, 'calories'),\n",
    "            \"total_fat_g\": get_nuntrient_value(nutrient_facts, 'fat'),\n",
    "            \"total_carbohydrates_g\": get_nuntrient_value(nutrient_facts, 'carbohydrate'),\n",
    "            \"protein_g\": get_nuntrient_value(nutrient_facts, 'protein'),\n",
    "            \"saturated_fat_g\": get_nuntrient_value(nutrient_facts, 'saturated_fat'),\n",
    "            \"dietary_fiber_g\": get_nuntrient_value(nutrient_facts, 'fibre'),\n",
    "            \"calcium\": get_nuntrient_value(nutrient_facts, 'calcium'),\n",
    "            \"trans_fat\": get_nuntrient_value(nutrient_facts, 'trans_fat'),\n",
    "            \"total_sugars\": get_nuntrient_value(nutrient_facts, 'sugars'),\n",
    "            \"iron\": get_nuntrient_value(nutrient_facts, 'iron'),\n",
    "            \"cholesterol\": get_nuntrient_value(nutrient_facts, 'cholesterol'),\n",
    "            \"vitaminD\": get_nuntrient_value(nutrient_facts, 'vitaminD'),\n",
    "            \"potassium\": get_nuntrient_value(nutrient_facts, 'potassium'),\n",
    "            \"sodium\": get_nuntrient_value(nutrient_facts, 'sodium'),\n",
    "            \"phosphorus\": get_nuntrient_value(nutrient_facts, 'phosphorus')\n",
    "        }\n",
    "\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_jsons_list = []\n",
    "\n",
    "for food_json in food_json_list:\n",
    "    data = structure_food_data(food_json['item'])\n",
    "    if data != None:\n",
    "        transformed_jsons_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_jsons_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load (L) Step\n",
    "In this step we are going to load the data to a Postgresql Database hosted in heroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_URL = os.environ.get('DATABASE_URL')\n",
    "\n",
    "df = pd.DataFrame(transformed_jsons_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DB_URL, echo=False)\n",
    "df.to_sql('macdonald_nutrients', con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "sql = \"SELECT * FROM macdonald_nutrients\"\n",
    "engine.execute(sql).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Big Breakfast with Hotcakes',),\n",
       " ('Vanilla Shake (Small)',),\n",
       " ('Caramel Macchiato (Small)',),\n",
       " ('Hotcakes and Sausage',),\n",
       " ('Hot Caramel Sundae',),\n",
       " ('Mango Pineapple Smoothie (Small)',),\n",
       " ('Hotcakes',),\n",
       " ('Frappe Mocha (Small)',),\n",
       " ('McFlurry with Oreo Cookies',),\n",
       " (\"McFlurry with M&M'S Chocolate Candies\",),\n",
       " ('Chocolate Shake (Small)',),\n",
       " ('Hot Fudge Sundae',),\n",
       " ('Mocha Caramel (Small)',),\n",
       " ('Strawberry Shake (Small)',),\n",
       " ('Strawberry Banana Smoothie (Small)',),\n",
       " ('Hot Chocolate (Small)',),\n",
       " ('FantaÂ® Orange (Small)',),\n",
       " ('Frappe Caramel (Small)',),\n",
       " ('Dr Pepper (Small)',),\n",
       " ('Cinnamon Roll',),\n",
       " ('Coca-Cola (Small)',)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a Analysis data\n",
    "sql = \"SELECT food_name FROM macdonald_nutrients WHERE total_sugars > 36\"\n",
    "engine.execute(sql).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above are the foods that over pass the recommended quantity of sugar daily.\n",
    "The American Heart Association recommends that people eat no more than 36 grams of sugar for most men and 24 grams for most women per day."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df71e190d7c24e7c839a0c4affcc352db52be118cf106aab1f73d5df6b2bc178"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
